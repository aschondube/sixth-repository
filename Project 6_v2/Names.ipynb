{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Customers' sex profiling derived from their first name\n",
    "\n",
    "This notebook explores how to profile customers to obtain their sex based on their name and the commonly associated sex to such names. It has been incorporated to the TablePrep notebook as it has proven succesful. If sucessful, will be incorporated into the \"Table_Preparation\" file.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevant module\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Collecting name data from US\n",
    "\n",
    "Note that customers are from US, so working with data from such country is preferred. There are paid services but this was a relatively easy way to skip through such services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0  1      2\n",
      "0         Emily  F  25735\n",
      "1       Jessica  F  21045\n",
      "2        Ashley  F  20896\n",
      "3         Sarah  F  20715\n",
      "4        Hannah  F  20595\n",
      "...         ... ..    ...\n",
      "867561    Zyell  M      5\n",
      "867562     Zyen  M      5\n",
      "867563   Zymirr  M      5\n",
      "867564   Zyquan  M      5\n",
      "867565    Zyrin  M      5\n",
      "\n",
      "[867566 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# baby name data for multiple years is obtained from US gov data → https://www.ssa.gov/oact/babynames/limits.html (note that using ChatGPT did not render correct results, responses for the intial names were accurate but as it progressed it simply assigned one single sex to all remainder names)\n",
    "\n",
    "#  list of file paths\n",
    "file_paths = [\n",
    "    'Names/yob1997.txt',\n",
    "    'Names/yob1998.txt',\n",
    "    'Names/yob1999.txt',\n",
    "    'Names/yob2000.txt',\n",
    "    'Names/yob2001.txt',\n",
    "    'Names/yob2002.txt',\n",
    "    'Names/yob2003.txt',\n",
    "    'Names/yob2004.txt',\n",
    "    'Names/yob2005.txt',\n",
    "    'Names/yob2006.txt',\n",
    "    'Names/yob2007.txt',\n",
    "    'Names/yob2008.txt',\n",
    "    'Names/yob2009.txt',\n",
    "    'Names/yob2010.txt',\n",
    "    'Names/yob2011.txt',\n",
    "    'Names/yob2012.txt',\n",
    "    'Names/yob2013.txt',\n",
    "    'Names/yob2014.txt',\n",
    "    'Names/yob2015.txt',\n",
    "    'Names/yob2016.txt',\n",
    "    'Names/yob2017.txt',\n",
    "    'Names/yob2018.txt',\n",
    "    'Names/yob2019.txt',\n",
    "    'Names/yob2020.txt',\n",
    "    'Names/yob2021.txt',\n",
    "    'Names/yob2022.txt',\n",
    "    'Names/yob2023.txt'\n",
    "]\n",
    "\n",
    "# list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# read each file into a DataFrame and append to the list\n",
    "for file_path in file_paths:\n",
    "    df = pd.read_csv(file_path, header=None)\n",
    "    dfs.append(df)\n",
    "\n",
    "# concat to join all DataFrames and expand the names across the list\n",
    "result_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "# \"master\" list of names\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns' labels \n",
    "result_df.rename(columns={0:'Name', 1:'Sex',2:'Popularity'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Collecting data from customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading customers file to conduct the match of names and sex for my customers_df \n",
    "customers_df= pd.read_csv('Customers.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Cleaning the data for matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerID       CustomerName      Segment First_Name\n",
      "0     CG-12520        Claire Gute     Consumer     Claire\n",
      "1     DV-13045    Darrin Van Huff    Corporate     Darrin\n",
      "2     SO-20335     Sean O'Donnell     Consumer       Sean\n",
      "3     BH-11710    Brosina Hoffman     Consumer    Brosina\n",
      "4     AA-10480       Andrew Allen     Consumer     Andrew\n",
      "..         ...                ...          ...        ...\n",
      "788   CJ-11875       Carl Jackson    Corporate       Carl\n",
      "789   RS-19870         Roy Skaria  Home Office        Roy\n",
      "790   SC-20845         Sung Chung     Consumer       Sung\n",
      "791   RE-19405    Ricardo Emerson     Consumer    Ricardo\n",
      "792   SM-20905  Susan MacKendrick     Consumer      Susan\n",
      "\n",
      "[793 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# splitting the Customer Name to obtain the first name based on spaces and dashes\n",
    "\n",
    "customers_df[['First_Name', _]] = customers_df['CustomerName'].str.split(r'\\s|-', n=1, expand=True)\n",
    "\n",
    "# dropping the second part (everything after the first space or dash)\n",
    "customers_df = customers_df.drop(columns=[_])\n",
    "\n",
    "print(customers_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 - Conducting the customer-common name match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerID       CustomerName      Segment First_Name  Sex\n",
      "0     CG-12520        Claire Gute     Consumer     Claire    F\n",
      "1     DV-13045    Darrin Van Huff    Corporate     Darrin    M\n",
      "2     SO-20335     Sean O'Donnell     Consumer       Sean    M\n",
      "3     BH-11710    Brosina Hoffman     Consumer    Brosina  NaN\n",
      "4     AA-10480       Andrew Allen     Consumer     Andrew    M\n",
      "..         ...                ...          ...        ...  ...\n",
      "788   CJ-11875       Carl Jackson    Corporate       Carl    M\n",
      "789   RS-19870         Roy Skaria  Home Office        Roy    M\n",
      "790   SC-20845         Sung Chung     Consumer       Sung    M\n",
      "791   RE-19405    Ricardo Emerson     Consumer    Ricardo    M\n",
      "792   SM-20905  Susan MacKendrick     Consumer      Susan    F\n",
      "\n",
      "[793 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# based on the first name fo the customers a sex is assigned which is commonly associated to such names   \n",
    "\n",
    "# Define a function to choose sex based on popularity for each group\n",
    "def choose_sex(group):\n",
    "    max_popularity_row = group.loc[group['Popularity'].idxmax()]\n",
    "    return max_popularity_row['Sex']\n",
    "\n",
    "# Group results_df by 'Name' and apply choose_sex function to each group\n",
    "max_popularity_df = result_df.groupby('Name').apply(choose_sex).reset_index()\n",
    "max_popularity_df.columns = ['First_Name', 'Sex']\n",
    "\n",
    "# Merge customers_df with max_popularity_df on 'First_Name' to assign sex based on popularity\n",
    "merged_df = pd.merge(customers_df, max_popularity_df, on='First_Name', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    793 non-null    object\n",
      " 1   CustomerName  793 non-null    object\n",
      " 2   Segment       793 non-null    object\n",
      " 3   First_Name    793 non-null    object\n",
      " 4   Sex           763 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 31.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# review of results to see if there are names without sex (i.e., non-null mismatch in Sex column)\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 - Dealing with missing names\n",
    "\n",
    "Given it is a considerable low volume the match for these names can either be done manually or with chatgpt (in this case results are accurate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CustomerID': {3: 'BH-11710',\n",
       "  9: 'ZD-21925',\n",
       "  27: 'KM-16720',\n",
       "  43: 'PN-18775',\n",
       "  114: 'Dl-13600',\n",
       "  164: 'SS-20140',\n",
       "  178: 'PO-19180',\n",
       "  190: 'XP-21865',\n",
       "  220: 'OT-18730',\n",
       "  233: 'ZC-21910',\n",
       "  237: 'CK-12205',\n",
       "  242: 'CK-12595',\n",
       "  261: 'RP-19390',\n",
       "  268: 'NP-18325',\n",
       "  285: 'PO-19195',\n",
       "  313: 'EM-14095',\n",
       "  316: 'CK-12760',\n",
       "  318: 'BK-11260',\n",
       "  337: 'SC-20050',\n",
       "  366: 'KM-16225',\n",
       "  368: 'DE-13255',\n",
       "  415: 'JR-15700',\n",
       "  460: 'DK-12835',\n",
       "  461: 'ST-20530',\n",
       "  521: 'HZ-14950',\n",
       "  524: 'FM-14215',\n",
       "  611: 'SG-20605',\n",
       "  652: 'MS-17530',\n",
       "  653: 'RH-19555',\n",
       "  721: 'LS-17230'},\n",
       " 'CustomerName': {3: 'Brosina Hoffman',\n",
       "  9: 'Zuschuss Donatelli',\n",
       "  27: 'Kunst Miller',\n",
       "  43: 'Parhena Norris',\n",
       "  114: 'Dorris liebe',\n",
       "  164: 'Saphhira Shifley',\n",
       "  178: 'Philisse Overcash',\n",
       "  190: 'Xylona Preis',\n",
       "  220: 'Olvera Toch',\n",
       "  233: 'Zuschuss Carroll',\n",
       "  237: 'Chloris Kastensmidt',\n",
       "  242: 'Clytie Kelty',\n",
       "  261: 'Resi Pölking',\n",
       "  268: 'Naresj Patel',\n",
       "  285: 'Phillina Ober',\n",
       "  313: 'Eudokia Martin',\n",
       "  316: 'Cyma Kinney',\n",
       "  318: 'Berenike Kampe',\n",
       "  337: 'Sample Company A',\n",
       "  366: 'Kalyca Meade',\n",
       "  368: 'Deanra Eno',\n",
       "  415: 'Jocasta Rupert',\n",
       "  460: 'Damala Kotsonis',\n",
       "  461: 'Shui Tom',\n",
       "  521: 'Henia Zydlo',\n",
       "  524: 'Filia McAdams',\n",
       "  611: 'Speros Goranitis',\n",
       "  652: 'MaryBeth Skach',\n",
       "  653: 'Ritsa Hightower',\n",
       "  721: 'Lycoris Saunders'},\n",
       " 'Segment': {3: 'Consumer',\n",
       "  9: 'Consumer',\n",
       "  27: 'Consumer',\n",
       "  43: 'Home Office',\n",
       "  114: 'Corporate',\n",
       "  164: 'Corporate',\n",
       "  178: 'Home Office',\n",
       "  190: 'Consumer',\n",
       "  220: 'Consumer',\n",
       "  233: 'Consumer',\n",
       "  237: 'Consumer',\n",
       "  242: 'Consumer',\n",
       "  261: 'Consumer',\n",
       "  268: 'Consumer',\n",
       "  285: 'Home Office',\n",
       "  313: 'Corporate',\n",
       "  316: 'Corporate',\n",
       "  318: 'Consumer',\n",
       "  337: 'Home Office',\n",
       "  366: 'Corporate',\n",
       "  368: 'Home Office',\n",
       "  415: 'Consumer',\n",
       "  460: 'Corporate',\n",
       "  461: 'Consumer',\n",
       "  521: 'Consumer',\n",
       "  524: 'Corporate',\n",
       "  611: 'Consumer',\n",
       "  652: 'Consumer',\n",
       "  653: 'Consumer',\n",
       "  721: 'Consumer'},\n",
       " 'First_Name': {3: 'Brosina',\n",
       "  9: 'Zuschuss',\n",
       "  27: 'Kunst',\n",
       "  43: 'Parhena',\n",
       "  114: 'Dorris',\n",
       "  164: 'Saphhira',\n",
       "  178: 'Philisse',\n",
       "  190: 'Xylona',\n",
       "  220: 'Olvera',\n",
       "  233: 'Zuschuss',\n",
       "  237: 'Chloris',\n",
       "  242: 'Clytie',\n",
       "  261: 'Resi',\n",
       "  268: 'Naresj',\n",
       "  285: 'Phillina',\n",
       "  313: 'Eudokia',\n",
       "  316: 'Cyma',\n",
       "  318: 'Berenike',\n",
       "  337: 'Sample',\n",
       "  366: 'Kalyca',\n",
       "  368: 'Deanra',\n",
       "  415: 'Jocasta',\n",
       "  460: 'Damala',\n",
       "  461: 'Shui',\n",
       "  521: 'Henia',\n",
       "  524: 'Filia',\n",
       "  611: 'Speros',\n",
       "  652: 'MaryBeth',\n",
       "  653: 'Ritsa',\n",
       "  721: 'Lycoris'},\n",
       " 'Sex': {3: nan,\n",
       "  9: nan,\n",
       "  27: nan,\n",
       "  43: nan,\n",
       "  114: nan,\n",
       "  164: nan,\n",
       "  178: nan,\n",
       "  190: nan,\n",
       "  220: nan,\n",
       "  233: nan,\n",
       "  237: nan,\n",
       "  242: nan,\n",
       "  261: nan,\n",
       "  268: nan,\n",
       "  285: nan,\n",
       "  313: nan,\n",
       "  316: nan,\n",
       "  318: nan,\n",
       "  337: nan,\n",
       "  366: nan,\n",
       "  368: nan,\n",
       "  415: nan,\n",
       "  460: nan,\n",
       "  461: nan,\n",
       "  521: nan,\n",
       "  524: nan,\n",
       "  611: nan,\n",
       "  652: nan,\n",
       "  653: nan,\n",
       "  721: nan}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtaining the names that did not have any match  \n",
    "merged_df[merged_df.isna().any(axis=1)].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    CustomerID       CustomerName      Segment First_Name Sex\n",
      "0     CG-12520        Claire Gute     Consumer     Claire   F\n",
      "1     DV-13045    Darrin Van Huff    Corporate     Darrin   M\n",
      "2     SO-20335     Sean O'Donnell     Consumer       Sean   M\n",
      "3     BH-11710    Brosina Hoffman     Consumer    Brosina   F\n",
      "4     AA-10480       Andrew Allen     Consumer     Andrew   M\n",
      "..         ...                ...          ...        ...  ..\n",
      "788   CJ-11875       Carl Jackson    Corporate       Carl   M\n",
      "789   RS-19870         Roy Skaria  Home Office        Roy   M\n",
      "790   SC-20845         Sung Chung     Consumer       Sung   M\n",
      "791   RE-19405    Ricardo Emerson     Consumer    Ricardo   M\n",
      "792   SM-20905  Susan MacKendrick     Consumer      Susan   F\n",
      "\n",
      "[793 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# filling out the 30 missing names with a commonly associated sex\n",
    "\n",
    "# Commonly associated sex based chatGPT's input\n",
    "common_sex = {\n",
    "    'Brosina': 'F',\n",
    "    'Zuschuss': 'M',\n",
    "    'Kunst': 'M',\n",
    "    'Parhena': 'F',\n",
    "    'Dorris': 'F',\n",
    "    'Saphhira': 'F',\n",
    "    'Philisse': 'F',\n",
    "    'Xylona': 'F',\n",
    "    'Olvera': 'M',\n",
    "    'Chloris': 'F',\n",
    "    'Clytie': 'F',\n",
    "    'Resi': 'F',\n",
    "    'Naresj': 'M',\n",
    "    'Phillina': 'F',\n",
    "    'Eudokia': 'F',\n",
    "    'Cyma': 'F',\n",
    "    'Berenike': 'F',\n",
    "    'Sample': 'M', # Assuming Sample as male\n",
    "    'Kalyca': 'F',\n",
    "    'Deanra': 'F',\n",
    "    'Jocasta': 'F',\n",
    "    'Damala': 'F',\n",
    "    'Shui': 'M',\n",
    "    'Henia': 'F',\n",
    "    'Filia': 'F',\n",
    "    'Speros': 'M',\n",
    "    'MaryBeth': 'F',\n",
    "    'Ritsa': 'F',\n",
    "    'Lycoris': 'F'\n",
    "}\n",
    "\n",
    "# Assign sex based on assumptions only for rows where 'Sex' column is NaN\n",
    "merged_df.loc[merged_df['Sex'].isnull(), 'Sex'] = merged_df.loc[merged_df['Sex'].isnull(), 'First_Name'].map(common_sex)\n",
    "\n",
    "# Display the DataFrame with assigned sex\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 793 entries, 0 to 792\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   CustomerID    793 non-null    object\n",
      " 1   CustomerName  793 non-null    object\n",
      " 2   Segment       793 non-null    object\n",
      " 3   First_Name    793 non-null    object\n",
      " 4   Sex           793 non-null    object\n",
      "dtypes: object(5)\n",
      "memory usage: 31.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# reviewing if there are any NaN values\n",
    "\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>Segment</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>JR-15700</td>\n",
       "      <td>Jocasta Rupert</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>Jocasta</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CustomerID    CustomerName   Segment First_Name Sex\n",
       "415   JR-15700  Jocasta Rupert  Consumer    Jocasta   F"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviewing NaN values for names without sex are now filled with one sample:\n",
    "\n",
    "merged_df[merged_df['First_Name']== 'Jocasta']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
